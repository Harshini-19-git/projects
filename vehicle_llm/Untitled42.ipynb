{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf sentence-transformers faiss-cpu openai google-generativeai\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from google.colab import files # Import files for upload\n",
        "import google.generativeai as genai # Import for Gemini API\n",
        "from google.colab import userdata # Import for Colab secrets\n",
        "\n",
        "# 1. PDF TEXT EXTRACTION  #\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # Check if the file exists before attempting to open\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"Error: The file '{pdf_path}' was not found.\")\n",
        "        print(\"Please upload your PDF manual.\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            raise FileNotFoundError(f\"No file uploaded. Expected '{pdf_path}'.\")\n",
        "        # Assuming the user uploads a single file and we want to use it\n",
        "        uploaded_filename = list(uploaded.keys())[0]\n",
        "        # If the uploaded file has a different name, rename it to 'manual.pdf'\n",
        "        if uploaded_filename != \"manual.pdf\":\n",
        "            os.rename(uploaded_filename, \"manual.pdf\")\n",
        "            print(f\"Uploaded file '{uploaded_filename}' renamed to 'manual.pdf'.\")\n",
        "        pdf_path = \"manual.pdf\" # Update path to the newly available file\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "\n",
        "###########################\n",
        "# 2. CHUNKING\n",
        "###########################\n",
        "\n",
        "def chunk_text(text, chunk_size=800, max_paragraph_words=500):\n",
        "    # Split text into paragraphs based on double newlines\n",
        "    paragraphs = re.split(r'\\n\\n+', text)\n",
        "    chunks = []\n",
        "\n",
        "    for para in paragraphs:\n",
        "        words = para.split()\n",
        "        if len(words) > max_paragraph_words:\n",
        "            # If a paragraph is too long, chunk it by words\n",
        "            chunks.extend([\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)])\n",
        "        elif len(words) > 0:\n",
        "            # Otherwise, keep the paragraph as a single chunk\n",
        "            chunks.append(\" \".join(words))\n",
        "    return chunks\n",
        "\n",
        "\n",
        "###########################\n",
        "# 2a. TEXT CLEANING\n",
        "###########################\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove multiple spaces, newlines, and tabs\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Convert to lowercase to ensure consistency for embedding and retrieval\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "\n",
        "###########################\n",
        "# 3. EMBEDDINGS + FAISS DB\n",
        "###########################\n",
        "\n",
        "def build_faiss_index(chunks):\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = model.encode(chunks)\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(np.array(embeddings))\n",
        "    return index, model\n",
        "\n",
        "\n",
        "###########################\n",
        "# 4. RETRIEVAL FUNCTION\n",
        "###########################\n",
        "\n",
        "def retrieve(query, index, model, chunks, k=3):\n",
        "    query_vec = model.encode([query])\n",
        "    distances, indices = index.search(np.array(query_vec), k)\n",
        "    return [chunks[i] for i in indices[0]]\n",
        "\n",
        "\n",
        "###########################\n",
        "# 5. LLM JSON EXTRACTION\n",
        "###########################\n",
        "\n",
        "def extract_structured_data(query, retrieved_text):\n",
        "    # WARNING: Hardcoding API keys is NOT RECOMMENDED for security reasons.\n",
        "    # It's best practice to use Colab secrets for API keys.\n",
        "    genai.configure(api_key=\"AIzaSyDmLIgHZ9-K3JbhGxsGBQ9jk9EjhFG9xFE\")\n",
        "\n",
        "    # Reverting to 'gemini-pro' as 'gemini-1.0-pro' was also not found.\n",
        "    # Check the output from genai.list_models() to confirm available models\n",
        "    gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Extract vehicle specifications from the following text based on the user's query.\n",
        "If the exact component from the query is not explicitly mentioned with a value,\n",
        "but a relevant value (e.g., torque) is found in close proximity to a general\n",
        "component (e.g., 'brakes' or 'disc brakes'), infer that general component.\n",
        "\n",
        "Return ONLY a JSON list with fields:\n",
        "component, spec_type, value, unit.\n",
        "\n",
        "If no relevant values are found, return an empty list [].\n",
        "\n",
        "Query: \"{query}\"\n",
        "\n",
        "Text:\n",
        "{retrieved_text}\n",
        "\"\"\"\n",
        "\n",
        "    response = gemini_model.generate_content(\n",
        "        prompt,\n",
        "        generation_config={\n",
        "            \"temperature\": 0\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "###########################\n",
        "# 6. MAIN EXECUTION\n",
        "###########################\n",
        "\n",
        "def run_pipeline(pdf_path, query):\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    print(\"--- Extracted Text ---\")\n",
        "    print(text[:500] + \"...\") # Print first 500 chars for brevity\n",
        "    print(\"----------------------\")\n",
        "\n",
        "    print(\"Cleaning text...\")\n",
        "    text = clean_text(text)\n",
        "    print(\"--- Cleaned Text ---\")\n",
        "    print(text[:500] + \"...\") # Print first 500 chars of cleaned text\n",
        "    print(\"--------------------\")\n",
        "\n",
        "    print(\"Chunking...\")\n",
        "    chunks = chunk_text(text)\n",
        "    print(\"--- Chunks (first 3) ---\")\n",
        "    for i, chunk in enumerate(chunks[:3]):\n",
        "        print(f\"Chunk {i+1}: {chunk[:200]}...\") # Print first 200 chars of each chunk\n",
        "    print(\"------------------------\")\n",
        "\n",
        "    # Add a check for empty chunks\n",
        "    if not chunks:\n",
        "        print(\"Error: No text could be extracted or chunked from the PDF. Cannot build FAISS index.\")\n",
        "        return\n",
        "\n",
        "    print(\"Building embeddings + FAISS index...\")\n",
        "    index, model = build_faiss_index(chunks)\n",
        "\n",
        "    print(\"Retrieving relevant chunks...\")\n",
        "    relevant_chunks = retrieve(query, index, model, chunks, k=3)\n",
        "    print(\"--- Retrieved Chunks ---\")\n",
        "    for i, chunk in enumerate(relevant_chunks):\n",
        "        print(f\"Relevant Chunk {i+1}: {chunk[:200]}...\") # Print first 200 chars of each relevant chunk\n",
        "    print(\"------------------------\")\n",
        "\n",
        "    retrieved_text = \"\\n\\n---\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    print(\"\\nAsking LLM to extract structure...\")\n",
        "    result = extract_structured_data(query, retrieved_text)\n",
        "\n",
        "    print(\"\\n================ JSON RESULT ================\")\n",
        "    print(result)\n",
        "    print(\"=============================================\")\n",
        "\n",
        "\n",
        "###########################\n",
        "# RUN PIPELINE\n",
        "###########################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"/content/sample-service-manual 1.pdf\"  # This path will be used, and if not found, upload will be prompted\n",
        "    query = \"Torque for brake caliper bolts\"\n",
        "    run_pipeline(pdf_path, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8gFGS7zfeYlf",
        "outputId": "3c84ba7f-eb3a-4997-85df-64b4456e27d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.6)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Extracting text from PDF...\n",
            "Error: The file '/content/sample-service-manual 1.pdf' was not found.\n",
            "Please upload your PDF manual.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2648aec7-5922-48db-8184-175c746f388e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2648aec7-5922-48db-8184-175c746f388e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample-service-manual 1.pdf to sample-service-manual 1.pdf\n",
            "Uploaded file 'sample-service-manual 1.pdf' renamed to 'manual.pdf'.\n",
            "--- Extracted Text ---\n",
            "Suspension System \n",
            "Inspection and Verification \n",
            "1.\n",
            "Road test. \n",
            "z Verify the customer concern by carrying out a road test on a smooth road. If any vibrations are \n",
            "apparent, refer to Section 100-04 . \n",
            "2.\n",
            "Inspect tires. \n",
            "z Check the tire pressure with all normal loads in the vehicle and the tires cold. Refer to the \n",
            "Vehicle Certification (VC) label. \n",
            "z Verify that all tires are sized to specification. Refer to the VC label. \n",
            "z Inspect the tires for incorrect wear and damage. Install new tires as ne...\n",
            "----------------------\n",
            "Cleaning text...\n",
            "--- Cleaned Text ---\n",
            "suspension system inspection and verification 1. road test. z verify the customer concern by carrying out a road test on a smooth road. if any vibrations are apparent, refer to section 100-04 . 2. inspect tires. z check the tire pressure with all normal loads in the vehicle and the tires cold. refer to the vehicle certification (vc) label. z verify that all tires are sized to specification. refer to the vc label. z inspect the tires for incorrect wear and damage. install new tires as necessary. ...\n",
            "--------------------\n",
            "Chunking...\n",
            "--- Chunks (first 3) ---\n",
            "Chunk 1: suspension system inspection and verification 1. road test. z verify the customer concern by carrying out a road test on a smooth road. if any vibrations are apparent, refer to section 100-04 . 2. ins...\n",
            "Chunk 2: the appropriate section in group 204 for the procedure. z damaged spring (s) z install new springs as necessary. refer to the appropriate section in group 204 for the procedure. z vehicle leans to one...\n",
            "Chunk 3: mounting brackets and shackles to remove any trapped debris. use compressed (shop) air to remove any remaining debris and to completely dry between all of the individual spring components. z shudder â€”...\n",
            "------------------------\n",
            "Building embeddings + FAISS index...\n",
            "Retrieving relevant chunks...\n",
            "--- Retrieved Chunks ---\n",
            "Relevant Chunk 1: to section 206-03 for front disc brakes or section 206-04 for rear disc brakes. 12. note: it is not required to install new brake pads if friction material is within specifications. for additional inf...\n",
            "Relevant Chunk 2: regulations. 1. note: use new copper washers. to install, tighten to 35 nm (26 lb-ft). 2. to install, tighten to 17 nm (150 lb-in). 3. to install, tighten to 30 nm (22 lb-ft). section 206-03: front di...\n",
            "Relevant Chunk 3: required) w713078 center bearing support bolt w713649 center bearing support nut 4a209 center bearing support shim 506545 shock absorber lower bolt w520214 shock absorber lower nut page 1 sur 3 2014 f...\n",
            "------------------------\n",
            "\n",
            "Asking LLM to extract structure...\n",
            "\n",
            "================ JSON RESULT ================\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"component\": \"front brake caliper bolts\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"37\",\n",
            "    \"unit\": \"nm\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"front brake caliper bolts\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"27\",\n",
            "    \"unit\": \"lb-ft\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"brake caliper flow bolt\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"35\",\n",
            "    \"unit\": \"nm\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"brake caliper flow bolt\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"26\",\n",
            "    \"unit\": \"lb-ft\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"brake caliper guide pin bolts\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"33\",\n",
            "    \"unit\": \"nm\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"brake caliper guide pin bolts\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"24\",\n",
            "    \"unit\": \"lb-ft\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"brake caliper support bracket bolts\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"150\",\n",
            "    \"unit\": \"nm\"\n",
            "  },\n",
            "  {\n",
            "    \"component\": \"brake caliper support bracket bolts\",\n",
            "    \"spec_type\": \"torque\",\n",
            "    \"value\": \"111\",\n",
            "    \"unit\": \"lb-ft\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "=============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kI1hptCojBab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}